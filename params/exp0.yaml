batch size: 128
device: cpu
dataroot: ../input/dataset/
dropout: 0.5
epoch: 300
optim: sgd
lr: 0.1
scheduler: torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.1)
thread: 2
seed: 2019
fold: 0
save path: /mnt/hdd1/hoge