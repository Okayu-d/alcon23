batch size: 128
device: cuda:0
dataroot: ../input/dataset/
dropout: 0.5
epoch: 300
optim: sgd
lr: 0.1
scheduler: torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.1)
thread: 4
seed: 2019
fold: 0